"""
ë‹¨ì¼ í†µí•© ì—ì´ì „íŠ¸

ëª¨ë“  ê¸°ëŠ¥ì„ í†µí•©í•œ ë‹¨ì¼ LangGraph ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
MCP ì„œë²„ë“¤ê³¼ ì—°ë™í•˜ì—¬ ì¢…í•©ì ì¸ ë°ì´í„° ìˆ˜ì§‘, ë¶„ì„, ì˜ì‚¬ê²°ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import asyncio
import logging
import os
from typing import Any, Dict, List, Optional

from langgraph.graph import END, START

from ..base import BaseGraphAgent
from ..base.mcp_config import MCPServerConfig, create_mcp_client_and_tools
from ..base.mcp_loader import MCPLoader
from .nodes import (
    collect_comprehensive_data,
    conversational_response,
    execute_action,
    make_intelligent_decision,
    perform_comprehensive_analysis,
    validate_request,
)
from .state import IntegratedAgentState, create_initial_state, get_state_summary

logger = logging.getLogger(__name__)


class IntegratedAgent(BaseGraphAgent):
    """ë‹¨ì¼ í†µí•© ì—ì´ì „íŠ¸"""

    def __init__(
        self,
        name: str = "integrated_agent",
        mcp_servers: Optional[List[str]] = None,
        config: Optional[Dict[str, Any]] = None,
        llm_model: Optional[str] = None,
        ollama_base_url: Optional[str] = None,
    ):
        """í†µí•© ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""

        # ê¸°ë³¸ MCP ì„œë²„ ëª©ë¡
        default_mcp_servers = [
            "macroeconomic",
            "financial_analysis",
            "stock_analysis",
            "naver_news",
            "tavily_search",
            "kiwoom",
        ]

        self.mcp_servers = mcp_servers or default_mcp_servers
        self.config = config or {}

        # LLM ëª¨ë¸ ì„¤ì •
        self.llm_model = llm_model or os.getenv("LLM_MODEL", "gpt-oss:20b")
        self.ollama_base_url = ollama_base_url or os.getenv(
            "OLLAMA_BASE_URL", "http://localhost:11434"
        )

        # MCP ì„œë²„ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        self.mcp_server_configs = MCPServerConfig.get_server_configs(self.mcp_servers)

        # MCP ë¡œë” ì´ˆê¸°í™”
        self.mcp_loader = MCPLoader(self.mcp_servers)

        # MCP í´ë¼ì´ì–¸íŠ¸ì™€ ë„êµ¬ë“¤ (ë‚˜ì¤‘ì— ì´ˆê¸°í™”)
        self.mcp_client = None
        self.mcp_tools = []

        super().__init__(
            name=name,
            mcp_servers=self.mcp_servers,
            config=self.config,
        )

        # LLM ì´ˆê¸°í™” (loggerê°€ ì´ˆê¸°í™”ëœ í›„)
        self.llm = self._setup_llm()

        self.logger.info(f"í†µí•© ì—ì´ì „íŠ¸ '{name}' ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"ë¡œì»¬ LLM ëª¨ë¸: {self.llm_model}")
        self.logger.info(f"MCP ì„œë²„ ì„¤ì •: {list(self.mcp_server_configs.keys())}")

    def _add_nodes(self):
        """ë…¸ë“œ ì¶”ê°€"""
        self.logger.info("í†µí•© ì—ì´ì „íŠ¸ ë…¸ë“œ ì¶”ê°€ ì‹œì‘")

        # ê° ë…¸ë“œì— ì—ì´ì „íŠ¸ ì°¸ì¡°ë¥¼ ì œê³µí•˜ëŠ” ë˜í¼ í•¨ìˆ˜ ìƒì„±
        async def validate_request_with_agent(state):
            return await validate_request(state)

        async def collect_data_with_agent(state):
            # MCP í´ë¼ì´ì–¸íŠ¸ì™€ ë„êµ¬ë“¤ì„ ë…¸ë“œì— ì „ë‹¬
            return await collect_comprehensive_data(
                state, mcp_client=self.mcp_client, mcp_tools=self.mcp_tools
            )

        async def analyze_data_with_agent(state):
            return await perform_comprehensive_analysis(state)

        async def make_decision_with_agent(state):
            # LLM ì‚¬ìš©ì´ í•„ìš”í•œ ë…¸ë“œì—ë§Œ agent ì°¸ì¡° ì „ë‹¬
            return await make_intelligent_decision(state, agent=self)

        async def execute_action_with_agent(state):
            return await execute_action(state)

        async def generate_response_with_agent(state):
            # ëŒ€í™”í˜• ì‘ë‹µ ìƒì„± ë…¸ë“œ - Ollama LLM í™œìš©
            return await conversational_response(state, agent=self)

        # ë…¸ë“œ ì¶”ê°€ (LangGraph ë¬¸ì„œì— ë”°ë¥¸ ë°©ì‹)
        self.workflow.add_node("validate_request", validate_request_with_agent)
        self.workflow.add_node("collect_data", collect_data_with_agent)
        self.workflow.add_node("analyze_data", analyze_data_with_agent)
        self.workflow.add_node("make_decision", make_decision_with_agent)
        self.workflow.add_node("execute_action", execute_action_with_agent)
        self.workflow.add_node("generate_response", generate_response_with_agent)

        self.logger.info("í†µí•© ì—ì´ì „íŠ¸ ë…¸ë“œ ì¶”ê°€ ì™„ë£Œ")

    def _add_edges(self):
        """ì—£ì§€ ì¶”ê°€"""
        self.logger.info("í†µí•© ì—ì´ì „íŠ¸ ì—£ì§€ ì—°ê²° ì‹œì‘")

        # LangGraph ë¬¸ì„œì— ë”°ë¥¸ ì—£ì§€ ì—°ê²° ë°©ì‹
        self.workflow.add_edge(START, "validate_request")
        self.workflow.add_edge("validate_request", "collect_data")
        self.workflow.add_edge("collect_data", "analyze_data")
        self.workflow.add_edge("analyze_data", "make_decision")
        self.workflow.add_edge("make_decision", "execute_action")
        self.workflow.add_edge("execute_action", "generate_response")
        self.workflow.add_edge("generate_response", END)

        self.logger.info("í†µí•© ì—ì´ì „íŠ¸ ì—£ì§€ ì—°ê²° ì™„ë£Œ")

    def _create_initial_state(self, **kwargs) -> Dict[str, Any]:
        """ì´ˆê¸° ìƒíƒœ ìƒì„±"""
        request = kwargs.get("request", {})
        task_type = kwargs.get("task_type", "comprehensive_analysis")

        return create_initial_state(request=request, task_type=task_type)

    def _get_state_type(self):
        """ìƒíƒœ íƒ€ì… ë°˜í™˜"""
        return IntegratedAgentState

    async def run_comprehensive_analysis(
        self, request: Dict[str, Any], task_type: str = "comprehensive_analysis"
    ) -> Dict[str, Any]:
        """ì¢…í•© ë¶„ì„ ì‹¤í–‰"""
        try:
            self.logger.info(f"ì¢…í•© ë¶„ì„ ì‹œì‘: {task_type}")

            # MCP ì„œë²„ë“¤ ì—°ê²°
            await self._connect_mcp_servers()

            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            result = await self.start(request=request, task_type=task_type)

            # ê²°ê³¼ ìš”ì•½ ìƒì„±
            summary = get_state_summary(result)

            self.logger.info(f"ì¢…í•© ë¶„ì„ ì™„ë£Œ: {summary}")

            # ğŸ” ê²°ê³¼ êµ¬ì¡° ìƒì„¸ ë””ë²„ê¹…
            self.logger.info("ğŸ” ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ ë¶„ì„:")
            self.logger.info(f"  - result íƒ€ì…: {type(result)}")
            self.logger.info(f"  - result í‚¤ë“¤: {list(result.keys()) if isinstance(result, dict) else 'dictê°€ ì•„ë‹˜'}")
            
            # ai_response ì°¾ê¸° (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„)
            ai_response = None
            if isinstance(result, dict):
                # ê²½ë¡œ 1: ì§ì ‘ ai_response
                if "ai_response" in result:
                    ai_response = result["ai_response"]
                    self.logger.info(f"  - ai_response ë°œê²¬ (ì§ì ‘): {len(ai_response) if isinstance(ai_response, str) else type(ai_response)} ë¬¸ì")
                # ê²½ë¡œ 2: metadataì—ì„œ ai_response
                elif "metadata" in result and isinstance(result["metadata"], dict) and "ai_response" in result["metadata"]:
                    ai_response = result["metadata"]["ai_response"]
                    self.logger.info(f"  - ai_response ë°œê²¬ (metadata): {len(ai_response) if isinstance(ai_response, str) else type(ai_response)} ë¬¸ì")
                    # ìµœìƒìœ„ë¡œ ë³µì‚¬
                    result["ai_response"] = ai_response
                else:
                    self.logger.warning("  - ai_responseë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ (ì§ì ‘ ë° metadata ëª¨ë‘ í™•ì¸)")
            else:
                self.logger.warning("  - resultê°€ dictê°€ ì•„ë‹˜")
                
            # ai_responseê°€ ìˆìœ¼ë©´ resultì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨
            if "ai_response" in result:
                result["ai_response"] = result["ai_response"]

            return {
                "success": True,
                "result": result,
                "summary": summary,
                "agent_name": self.name,
            }

        except Exception as e:
            self.logger.error(f"ì¢…í•© ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e), "agent_name": self.name}
        finally:
            # MCP ì„œë²„ë“¤ ì—°ê²° í•´ì œ
            await self._disconnect_mcp_servers()

    async def run_data_collection(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ë°ì´í„° ìˆ˜ì§‘ë§Œ ì‹¤í–‰"""
        return await self.run_comprehensive_analysis(
            request=request, task_type="data_collection"
        )

    async def run_market_analysis(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹œì¥ ë¶„ì„ë§Œ ì‹¤í–‰"""
        return await self.run_comprehensive_analysis(
            request=request, task_type="market_analysis"
        )

    async def run_investment_decision(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """íˆ¬ì ì˜ì‚¬ê²°ì •ë§Œ ì‹¤í–‰"""
        return await self.run_comprehensive_analysis(
            request=request, task_type="investment_decision"
        )

    async def run_trading_execution(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ê±°ë˜ ì‹¤í–‰ë§Œ ì‹¤í–‰"""
        return await self.run_comprehensive_analysis(
            request=request, task_type="trading_execution"
        )

    def get_agent_info(self) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ì •ë³´ ë°˜í™˜"""
        return {
            "name": self.name,
            "type": "integrated_agent",
            "description": "ì¢…í•©ì ì¸ ë°ì´í„° ìˆ˜ì§‘, ë¶„ì„, ì˜ì‚¬ê²°ì •ì„ ìˆ˜í–‰í•˜ëŠ” í†µí•© ì—ì´ì „íŠ¸",
            "capabilities": [
                "ë°ì´í„° ìˆ˜ì§‘ (ê±°ì‹œê²½ì œ, ì¬ë¬´, ì£¼ì‹, ë‰´ìŠ¤, ê²€ìƒ‰)",
                "ì¢…í•© ë¶„ì„ (ê¸°ìˆ ì , ê¸°ë³¸ì , ê°ì •, ì‹œì¥)",
                "ì§€ëŠ¥ì  ì˜ì‚¬ê²°ì •",
                "ì•¡ì…˜ ì‹¤í–‰",
            ],
            "mcp_servers": self.mcp_loader.mcp_servers,
            "workflow_steps": [
                "validate_request",
                "collect_data",
                "analyze_data",
                "make_decision",
                "execute_action",
            ],
            "status": "ready",
        }

    async def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        return {
            "agent_name": self.name,
            "total_executions": 0,  # ì‹¤ì œë¡œëŠ” ì¹´ìš´í„° í•„ìš”
            "success_rate": 1.0,
            "average_execution_time": 30.0,  # ì´ˆ
            "last_execution": None,
            "mcp_connections": self.mcp_loader.get_connection_summary(),
            "error_count": self.error_handler.get_error_count(),
        }

    async def _connect_mcp_servers(self):
        """MCP ì„œë²„ë“¤ ì—°ê²°"""
        try:
            self.logger.info("MCP ì„œë²„ ì—°ê²° ì‹œì‘")

            # MCP ë¡œë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë²„ë“¤ ì—°ê²°
            await self.mcp_loader.connect_all()

            # MCP í´ë¼ì´ì–¸íŠ¸ì™€ ë„êµ¬ë“¤ ìƒì„±
            self.mcp_client, self.mcp_tools = await create_mcp_client_and_tools(
                self.mcp_server_configs
            )
            self.logger.info(
                f"MCP ì„œë²„ ì—°ê²° ì™„ë£Œ: {len(self.mcp_loader.connected_servers)}ê°œ"
            )
            self.logger.info(f"MCP ë„êµ¬ ë¡œë”© ì™„ë£Œ: {len(self.mcp_tools)}ê°œ")

        except Exception as e:
            self.logger.error(f"MCP ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise

    async def _disconnect_mcp_servers(self):
        """MCP ì„œë²„ë“¤ ì—°ê²° í•´ì œ"""
        try:
            self.logger.info("MCP ì„œë²„ ì—°ê²° í•´ì œ ì‹œì‘")

            # MCP ë¡œë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë²„ë“¤ ì—°ê²° í•´ì œ
            await self.mcp_loader.disconnect_all()

            # í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
            self.mcp_client = None
            self.mcp_tools = []

            self.logger.info("MCP ì„œë²„ ì—°ê²° í•´ì œ ì™„ë£Œ")

        except Exception as e:
            self.logger.error(f"MCP ì„œë²„ ì—°ê²° í•´ì œ ì‹¤íŒ¨: {e}")

    async def health_check(self) -> Dict[str, Any]:
        """í—¬ìŠ¤ ì²´í¬"""
        try:
            # MCP ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸
            mcp_status = {}
            for server in self.mcp_loader.mcp_servers:
                is_connected = self.mcp_loader.is_server_connected(server)
                mcp_status[server] = "connected" if is_connected else "disconnected"

            return {
                "status": "healthy",
                "agent_name": self.name,
                "workflow_ready": self.workflow is not None,
                "mcp_servers": mcp_status,
                "error_count": self.error_handler.get_error_count(),
                "timestamp": asyncio.get_event_loop().time(),
            }

        except Exception as e:
            return {
                "status": "unhealthy",
                "agent_name": self.name,
                "error": str(e),
                "timestamp": asyncio.get_event_loop().time(),
            }

    def _setup_llm(self) -> Any:
        """ë¡œì»¬ Ollama LLM ëª¨ë¸ ì„¤ì •"""
        try:
            # Ollama ëª¨ë¸ ì´ˆê¸°í™”
            from langchain_community.llms import Ollama

            # Ollama ê¸°ë°˜ ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©
            llm = Ollama(
                model=self.llm_model,  # ë¡œì»¬ Ollama ëª¨ë¸ëª…
                temperature=0.1,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ëœ ê²°ê³¼
                base_url=self.ollama_base_url,  # ì„¤ì •ëœ Ollama URL ì‚¬ìš©
            )

            self.logger.info(f"ë¡œì»¬ Ollama LLM ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ: {self.llm_model}")
            return llm

        except ImportError:
            self.logger.error(
                "langchain_community íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install langchain-community'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”."
            )
            return None
        except Exception as e:
            self.logger.error(f"ë¡œì»¬ Ollama LLM ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.logger.info("Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”: 'ollama serve'")
            return None
