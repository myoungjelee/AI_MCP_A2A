# ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ MCP ì„œë²„ í•™ìŠµ ê°€ì´ë“œ

## ğŸ“š **ì „ì²´ êµ¬ì¡°**

ì´ MCP ì„œë²„ëŠ” **ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ**ìœ¼ë¡œ êµ¬í˜„ë˜ì–´ ìˆìœ¼ë©°, ê°œë°œ ê¸°ìˆ  ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

```
macroeconomic/
â”œâ”€â”€ client.py          # ë°ì´í„° ì²˜ë¦¬ í´ë¼ì´ì–¸íŠ¸
â”œâ”€â”€ server.py          # FastMCP ê¸°ë°˜ ì„œë²„
â”œâ”€â”€ __init__.py        # ëª¨ë“ˆ ì´ˆê¸°í™” ë° export
â””â”€â”€ LEARNING_GUIDE.md  # ì´ í•™ìŠµ ê°€ì´ë“œ
```

## ğŸ—ï¸ **í•µì‹¬ í´ë˜ìŠ¤**

### **DataProcessingClient**

**ì—­í• **: ë°ì´í„° ìˆ˜ì§‘, ë°°ì¹˜ ì²˜ë¦¬, íŠ¸ë Œë“œ ë¶„ì„ì„ ë‹´ë‹¹í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸

**ì£¼ìš” íŠ¹ì§•**:

- `BaseMCPClient` ìƒì†ìœ¼ë¡œ MCP í‘œì¤€ ì¤€ìˆ˜
- ë¹„ë™ê¸° ì²˜ë¦¬ (`async/await`)
- ìºì‹± ì‹œìŠ¤í…œ (TTL ê¸°ë°˜, 5ë¶„)
- ì¬ì‹œë„ ë¡œì§ (ì§€ìˆ˜ ë°±ì˜¤í”„, ìµœëŒ€ 3íšŒ)
- ì„ í˜• íšŒê·€ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„

**í•µì‹¬ ë©”ì„œë“œ**:

```python
async def collect_data(category: str, max_records: int, source: str)
async def process_data_batch(data_records: List[Dict], operation: str)
async def analyze_data_trends(data_records: List[Dict])
```

## ğŸ”§ **ì£¼ìš” ê¸°ìˆ  êµ¬í˜„**

### **1. ìºì‹± ì‹œìŠ¤í…œ**

```python
def _get_cache_key(self, func_name: str, **kwargs) -> str:
    """ìºì‹œ í‚¤ ìƒì„±"""
    params_str = "&".join([f"{k}={v}" for k, v in sorted(kwargs.items())])
    return f"{func_name}:{params_str}"

def _is_cache_valid(self, cache_key: str) -> bool:
    """ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬"""
    if cache_key not in self._cache_timestamps:
        return False

    elapsed = time.time() - self._cache_timestamps[cache_key]
    return elapsed < self._cache_ttl  # 5ë¶„(300ì´ˆ)
```

**í•™ìŠµ í¬ì¸íŠ¸**:

- ìºì‹œ í‚¤ ìƒì„± ì „ëµ
- TTL ê¸°ë°˜ ìºì‹œ ë§Œë£Œ (5ë¶„)
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ìºì‹œ ê´€ë¦¬

### **2. ì¬ì‹œë„ ë¡œì§**

```python
async def _retry_with_backoff(self, func, *args, max_retries: int = 3, **kwargs):
    """ì§€ìˆ˜ ë°±ì˜¤í”„ë¥¼ ì‚¬ìš©í•œ ì¬ì‹œë„ ë¡œì§"""
    for attempt in range(max_retries):
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            if attempt == max_retries - 1:
                raise

            wait_time = 2 ** attempt  # 1ì´ˆ â†’ 2ì´ˆ â†’ 4ì´ˆ
            logger.warning(f"Attempt {attempt + 1} failed, retrying in {wait_time}s: {e}")
            await asyncio.sleep(wait_time)
```

**í•™ìŠµ í¬ì¸íŠ¸**:

- ì§€ìˆ˜ ë°±ì˜¤í”„ ì•Œê³ ë¦¬ì¦˜ (1ì´ˆ â†’ 2ì´ˆ â†’ 4ì´ˆ)
- ë¹„ë™ê¸° í•¨ìˆ˜ì˜ ì¬ì‹œë„ ì²˜ë¦¬ (ìµœëŒ€ 3íšŒ)
- ë¡œê¹…ì„ í†µí•œ ë””ë²„ê¹… ì§€ì›

### **3. ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ**

```python
async def process_data_batch(self, data_records: List[Dict], operation: str):
    """ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬"""
    # ë°°ì¹˜ í¬ê¸° ìµœì í™” (ìµœëŒ€ 100ê°œ)
    batch_size = min(100, len(data_records))

    for i in range(0, len(data_records), batch_size):
        batch = data_records[i:i + batch_size]
        # ë°°ì¹˜ë³„ ì²˜ë¦¬ ë¡œì§
```

**í•™ìŠµ í¬ì¸íŠ¸**:

- ë°°ì¹˜ í¬ê¸° ìµœì í™” (ìµœëŒ€ 100ê°œ)
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²˜ë¦¬
- ì—ëŸ¬ ê²©ë¦¬ ë° ë³µêµ¬

### **4. ì„ í˜• íšŒê·€ ì•Œê³ ë¦¬ì¦˜**

```python
def _calculate_linear_regression(self, values: List[float], timestamps: List[datetime]):
    """ì„ í˜• íšŒê·€ ê³„ì‚°"""
    n = len(values)
    x = list(range(n))
    y = values

    # í‰ê·  ê³„ì‚°
    x_mean = sum(x) / n
    y_mean = sum(y) / n

    # ê¸°ìš¸ê¸°ì™€ ì ˆí¸ ê³„ì‚°
    numerator = sum((x[i] - x_mean) * (y[i] - y_mean) for i in range(n))
    denominator = sum((x[i] - x_mean) ** 2 for i in range(n))

    if denominator != 0:
        slope = numerator / denominator
        intercept = y_mean - slope * x_mean
```

**í•™ìŠµ í¬ì¸íŠ¸**:

- ìˆ˜í•™ì  ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
- í†µê³„ ê³„ì‚° (í‰ê· , ë¶„ì‚°, í‘œì¤€í¸ì°¨)
- R-squared ê³„ì‚°
- ì˜ˆì¸¡ ëª¨ë¸ êµ¬í˜„

### **5. ë°ì´í„° êµ¬ì¡°í™”**

```python
@dataclass
class DataRecord:
    """ë°ì´í„° ë ˆì½”ë“œ êµ¬ì¡°"""
    id: str
    timestamp: datetime
    value: float
    category: str
    source: str
    metadata: Dict[str, Any]
```

**í•™ìŠµ í¬ì¸íŠ¸**:

- `@dataclass` ë°ì½”ë ˆì´í„° í™œìš©
- íƒ€ì… íŒíŠ¸ë¥¼ í†µí•œ ëª…í™•í•œ ë°ì´í„° êµ¬ì¡°
- ì§ë ¬í™” ê°€ëŠ¥í•œ ë°ì´í„° ëª¨ë¸

## ğŸ” **ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ ê¸°ëŠ¥**

### **1. ë°ì´í„° ìˆ˜ì§‘**

```python
async def collect_data(self, category: str, max_records: int = 100, source: str = "default"):
    """ë°ì´í„° ìˆ˜ì§‘ - ì‹¤ì œ ë°ì´í„° ì‚¬ìš©"""
    return {
        "success": True,
        "category": category,
        "source": source,
        "total_collected": len(records),
        "records": [
            {
                "id": record.id,
                "timestamp": record.timestamp.isoformat(),
                "value": record.value,
                "category": record.category,
                "source": record.source,
                "metadata": record.metadata,
            }
            for record in records
        ],
        "collection_timestamp": datetime.now().isoformat(),
    }
```

### **2. ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬**

```python
async def process_data_batch(self, data_records: List[Dict], operation: str = "validate"):
    """ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬"""
    return {
        "success": len(errors) == 0,
        "operation": operation,
        "total_records": len(data_records),
        "processed_count": processed_count,
        "batch_size": batch_size,  # ìµœëŒ€ 100ê°œ
        "processing_time": round(processing_time, 3),
        "results": results,
        "errors": errors,
        "processing_timestamp": datetime.now().isoformat(),
    }
```

### **3. ë°ì´í„° íŠ¸ë Œë“œ ë¶„ì„**

```python
async def analyze_data_trends(self, data_records: List[Dict]):
    """ë°ì´í„° íŠ¸ë Œë“œ ë¶„ì„ (ì„ í˜• íšŒê·€ ì•Œê³ ë¦¬ì¦˜)"""
    return {
        "success": True,
        "trend_analysis": {
            "slope": round(slope, 4),
            "intercept": round(intercept, 4),
            "trend_direction": trend_direction,  # "ìƒìŠ¹", "í•˜ë½", "ì•ˆì •"
            "trend_strength": trend_strength,    # "ê°•í•¨", "ì•½í•¨"
            "r_squared": r_squared,
            "predicted_next_value": round(predicted_value, 2),
            "confidence": "ë†’ìŒ" if abs(slope) > 0.05 else "ë³´í†µ",
        },
        "statistics": statistics,
        "data_summary": {
            "total_records": len(data_records),
            "valid_records": len(values),
            "time_range": {
                "start": timestamps[0].isoformat(),
                "end": timestamps[-1].isoformat(),
            },
        },
        "analysis_timestamp": datetime.now().isoformat(),
    }
```

## ğŸš€ **FastMCP ì„œë²„ êµ¬í˜„**

### **DataProcessingMCPServer**

**í•µì‹¬ íŠ¹ì§•**:

- `FastMCP` ì§ì ‘ ì‚¬ìš© (ìƒì† ì—†ìŒ)
- í¬íŠ¸ 8041 ì‚¬ìš©
- ë„êµ¬ ë“±ë¡ì„ í†µí•œ ê¸°ëŠ¥ ë…¸ì¶œ
- ë¹„ë™ê¸° ë„êµ¬ ì‹¤í–‰

**ë„êµ¬ ë“±ë¡ íŒ¨í„´**:

```python
@self.mcp.tool()
async def collect_data(category: str, max_records: int = 100, source: str = "default"):
    """ë°ì´í„° ìˆ˜ì§‘ ë„êµ¬"""
    try:
        result = await self.client.collect_data(
            category=category,
            max_records=max_records,
            source=source
        )
        return result
    except Exception as e:
        logger.error(f"collect_data failed: {e}")
        return {"success": False, "error": str(e), "category": category}
```

## ğŸ“– **í•™ìŠµ ìˆœì„œ**

### **1ë‹¨ê³„: ê¸°ë³¸ êµ¬ì¡° ì´í•´**

1. `__init__.py`ì—ì„œ ì „ì²´ ëª¨ë“ˆ êµ¬ì¡° íŒŒì•…
2. `client.py`ì˜ í´ë˜ìŠ¤ êµ¬ì¡°ì™€ ë©”ì„œë“œ ì´í•´
3. `server.py`ì˜ FastMCP ì„œë²„ êµ¬í˜„ ë°©ì‹ í•™ìŠµ

### **2ë‹¨ê³„: í•µì‹¬ ê¸°ìˆ  í•™ìŠµ**

1. **ìºì‹± ì‹œìŠ¤í…œ**: `_get_cache_key`, `_is_cache_valid` ë©”ì„œë“œ
2. **ì¬ì‹œë„ ë¡œì§**: `_retry_with_backoff` ë©”ì„œë“œ
3. **ë°°ì¹˜ ì²˜ë¦¬**: `process_data_batch` ë©”ì„œë“œ
4. **ì•Œê³ ë¦¬ì¦˜**: `_calculate_linear_regression` ë©”ì„œë“œ
5. **ë°ì´í„° êµ¬ì¡°**: `DataRecord` dataclass

### **3ë‹¨ê³„: ê³ ê¸‰ ê¸°ëŠ¥ í•™ìŠµ**

1. **í†µê³„ ê³„ì‚°**: `_calculate_statistics` ë©”ì„œë“œ
2. **R-squared**: `_calculate_r_squared` ë©”ì„œë“œ
3. **ë°°ì¹˜ ìµœì í™”**: ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸°ì™€ ì²˜ë¦¬ ë°©ì‹

## ğŸ’¡ **ì‹¤ìš© ì˜ˆì‹œ**

### **ë°ì´í„° ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°**

```python
# 1. ë°ì´í„° ìˆ˜ì§‘
collection_result = await client.collect_data(
    category="performance",
    max_records=100,
    source="system_monitor"
)

# 2. ë°°ì¹˜ ì²˜ë¦¬
processing_result = await client.process_data_batch(
    collection_result["records"],
    operation="validate"
)

# 3. íŠ¸ë Œë“œ ë¶„ì„
trend_result = await client.analyze_data_trends(
    processing_result["results"]
)
```

### **ì„ í˜• íšŒê·€ ê²°ê³¼ í•´ì„**

```python
trend_analysis = trend_result["trend_analysis"]

print(f"íŠ¸ë Œë“œ ë°©í–¥: {trend_analysis['trend_direction']}")
print(f"íŠ¸ë Œë“œ ê°•ë„: {trend_analysis['trend_strength']}")
print(f"ê¸°ìš¸ê¸°: {trend_analysis['slope']}")
print(f"R-squared: {trend_analysis['r_squared']}")
print(f"ë‹¤ìŒ ì˜ˆì¸¡ê°’: {trend_analysis['predicted_next_value']}")
```

## ğŸ¯ **í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸**

### **1. MCP í‘œì¤€ ì¤€ìˆ˜**

- `BaseMCPClient` ìƒì†ìœ¼ë¡œ í‘œì¤€ ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
- `list_tools()`, `call_tool()` ë©”ì„œë“œ êµ¬í˜„

### **2. ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°**

- `asyncio`ë¥¼ í™œìš©í•œ ë¹„ë™ê¸° ì²˜ë¦¬
- ë™ì‹œì„±ê³¼ ì„±ëŠ¥ ìµœì í™”

### **3. ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„**

- ì„ í˜• íšŒê·€ ì•Œê³ ë¦¬ì¦˜ì˜ ìˆ˜í•™ì  êµ¬í˜„
- í†µê³„ ê³„ì‚° ë° ì˜ˆì¸¡ ëª¨ë¸

### **4. ì„±ëŠ¥ ìµœì í™”**

- ë°°ì¹˜ ì²˜ë¦¬ë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„° íš¨ìœ¨ì  ì²˜ë¦¬ (ìµœëŒ€ 100ê°œ)
- ìºì‹±ì„ í†µí•œ ì¤‘ë³µ ìš”ì²­ ë°©ì§€ (5ë¶„ TTL)
- ì¬ì‹œë„ ë¡œì§ìœ¼ë¡œ ì•ˆì •ì„± í–¥ìƒ (3íšŒ ìµœëŒ€)

### **5. ì—ëŸ¬ ì²˜ë¦¬**

- ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤ ì •ì˜
- ì²´ê³„ì ì¸ ì—ëŸ¬ ë¡œê¹… ë° ì‘ë‹µ
- ë°°ì¹˜ë³„ ì—ëŸ¬ ê²©ë¦¬

## ğŸš€ **ë‹¤ìŒ ë‹¨ê³„**

### **1. í™•ì¥ ê°€ëŠ¥í•œ ê¸°ëŠ¥**

- ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ (ë¡œì§€ìŠ¤í‹± íšŒê·€, ëœë¤ í¬ë ˆìŠ¤íŠ¸)
- ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°
- ë¶„ì‚° ì²˜ë¦¬ ë° ë³‘ë ¬í™”

### **2. ê³ ê¸‰ ê¸°ìˆ  ì ìš©**

- Redisë¥¼ í™œìš©í•œ ë¶„ì‚° ìºì‹±
- ë©”ì‹œì§€ íë¥¼ í†µí•œ ë¹„ë™ê¸° ì²˜ë¦¬
- ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘

### **3. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦**

- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- í†µí•© í…ŒìŠ¤íŠ¸ êµ¬í˜„
- ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ìµœì í™”

## ğŸ› **ë””ë²„ê¹… íŒ**

### **1. ë¡œê·¸ í™•ì¸**

```python
# ë¡œê·¸ ë ˆë²¨ ì„¤ì •
logging.basicConfig(level=logging.INFO)

# íŠ¹ì • ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
```

### **2. ìºì‹œ ë””ë²„ê¹…**

```python
# ìºì‹œ ìƒíƒœ í™•ì¸
print(f"Cache keys: {list(client._cache.keys())}")
print(f"Cache timestamps: {client._cache_timestamps}")
print(f"Cache TTL: {client._cache_ttl}ì´ˆ")
```

### **3. ì•Œê³ ë¦¬ì¦˜ ë””ë²„ê¹…**

```python
# ì„ í˜• íšŒê·€ ê³„ì‚° ê³¼ì • í™•ì¸
values = [100, 101, 102, 103, 104]
x = list(range(len(values)))
print(f"Values: {values}")
print(f"X coordinates: {x}")

# ê¸°ìš¸ê¸° ê³„ì‚° í™•ì¸
slope = client._calculate_linear_regression(values, [datetime.now()] * len(values))
print(f"Calculated slope: {slope['slope']}")
```

### **4. ë°°ì¹˜ ì²˜ë¦¬ ë””ë²„ê¹…**

```python
# ë°°ì¹˜ í¬ê¸° í™•ì¸
batch_size = min(100, len(data_records))  # ìµœëŒ€ 100ê°œ
print(f"Total records: {len(data_records)}")
print(f"Batch size: {batch_size}")
print(f"Number of batches: {len(data_records) // batch_size + 1}")
```

## ğŸ“š **ì°¸ê³  ìë£Œ**

- [FastMCP ê³µì‹ ë¬¸ì„œ](https://github.com/fastmcp/fastmcp)
- [Python asyncio ê°€ì´ë“œ](https://docs.python.org/3/library/asyncio.html)
- [Python dataclasses](https://docs.python.org/3/library/dataclasses.html)
- [ì„ í˜• íšŒê·€ ìˆ˜í•™](https://en.wikipedia.org/wiki/Linear_regression)
- [MCP í”„ë¡œí† ì½œ ìŠ¤í™](https://modelcontextprotocol.io/)

---

**ì´ í•™ìŠµ ê°€ì´ë“œëŠ” ê°œë°œ ê¸°ìˆ  ì¤‘ì‹¬ì˜ MCP ì„œë²„ êµ¬í˜„ì„ ìœ„í•œ ê²ƒì…ë‹ˆë‹¤.**
**ë„ë©”ì¸ ì§€ì‹ë³´ë‹¤ëŠ” MCP, FastMCP, ë¹„ë™ê¸° ì²˜ë¦¬, ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ ë“±ì˜ ê°œë°œ ê¸°ìˆ ì— ì§‘ì¤‘í•˜ì—¬ í•™ìŠµí•˜ì„¸ìš”.**
